# -*- coding: utf-8 -*-
"""Big Sales Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cr3yiVOpZ76kVCLwRboVRVVjTUzw_3ly

# **Big Sales Prediction using Random Forest Regressor**

# **Get Understanding about Data Set**

**There are 12 variables in dataset**.
1. Item_Identifier
2. Item_Weight
3. Item_Fat_Content
4. Item_Visibility
5. Item_Type
6. Item_MRP
7. Outlet_Identifier
8. Outlet_Establishment_Year
9. Outlet_Size
10. Outlet_Location_Type
11. Outlet_Type
12. Item_Outlet_Sales

# **Import Library**
"""

import pandas as pd

import numpy as np

"""# **Import CSV as DataFrame**

**Use URL of file directly**
"""

df = pd.read_csv(r'/content/sample_data/Big Sales Data.csv')

"""**Or use local path in Jupyter Notebook**"""

# df = pd.read_csv(r'D:\D_____Data_Analyst\Internship\Final Intership Projects\Big Sales Prediction\Big Sales Data.csv')

"""**or use file path after uploading file in Google Colab Notebook**"""

# df = pd.read_csv(r'/content/Big Sales Data.csv')

"""# **Get the First Five Rows of DataFrame**"""

df.head()

"""# **Get Information of DataFrame**"""

df.info()

"""# **Get Column Names**"""

df.columns

"""# **Get the Summary Statistics**"""

df.describe()

"""# **Get Missing Values Complete**"""

df['Item_Weight'].fillna(df.groupby(['Item_Type'])['Item_Weight'].transform('mean'), inplace=True)

df.info()

df.describe()

import seaborn as sns

sns.pairplot(df)

"""# **Get Categories and Counts of Categorical Variables**"""

df[['Item_Identifier']].value_counts()

df[['Item_Fat_Content']].value_counts()

df.replace({'Item_Fat_Content': {'LF':'Low Fat', 'reg':'Regular', 'low fat':'Low Fat'}}, inplace=True)

df[['Item_Fat_Content']].value_counts()

df.replace({'Item_Fat_Content': {'Low Fat': 0, 'Regular' : 1}}, inplace=True)

df[['Item_Type']].value_counts()

df.replace({'Item_Type':{'Fruits and Vegetables':0, 'Snack Foods':0, 'Household':1,'Frozen Foods':0, 'Dairy':0, 'Baking Goods':0, 'Canned':0,'Health and Hygiene':1, 'Meat':0, 'Soft Drinks':0,'Breads':0, 'Hard Drinks':0, 'Others':2, 'Starchy Foods':0, 'Breakfast':0, 'Seafood':0}}, inplace=True)

df[['Item_Type']].value_counts()

df[['Outlet_Identifier']].value_counts()

df.replace({'Outlet_Identifier' : {'OUT027' : 0, 'OUT013' : 1, 'OUT049' : 2, 'OUT046' : 3, 'OUT035' : 4, 'OUT045' : 5, 'OUT018' : 6, 'OUT017' : 7, 'OUT010' : 8, 'OUT019' : 9}}, inplace=True)

df[['Outlet_Identifier']].value_counts()

df[['Outlet_Size']].value_counts()

df.replace({'Outlet_Size': {'Small':0, 'Medium':1, 'High':2}}, inplace=True)

df[['Outlet_Size']].value_counts()

df[['Outlet_Location_Type']].value_counts()

df.replace({'Outlet_Location_Type' : {'Tier 1':0, 'Tier 2':1,'Tier 3':2}}, inplace=True)

df[['Outlet_Location_Type']].value_counts()

df[['Outlet_Type']].value_counts()

df.replace({'Outlet_Type': {'Grocery Store': 0, 'Supermarket Type1':1, 'Supermarket Type2':2,'Supermarket Type3':3}}, inplace=True)

df[['Outlet_Type']].value_counts()

df.head()

df.info()

"""# **Get Shape of DataFrame**"""

df.shape

"""# **Define y (dependent or label or target variable) and x (independent or features or attribute Variable)**"""

y = df['Item_Outlet_Sales']

y.shape

y

x = df[['Item_Weight', 'Item_Fat_Content', 'Item_Visibility', 'Item_Type', 'Item_MRP', 'Outlet_Identifier', 'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']]

"""## or use .drop function to define x"""

x = df.drop(['Item_Identifier', 'Item_Outlet_Sales'], axis=1)

x.shape

x

"""# **Get X Variables Standardized**

Standardization of datasets is a common requirement for many machine learning setimators implemented in scikit-learn, they might behave badly if the individual features do not more or less look like standard normally distributed data Gaussian with zero mean and unit variance.
"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

x_std = df[['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']]

x_std = sc.fit_transform(x_std)

x_std

x[['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']] = pd.DataFrame(x_std, columns = [['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']])

x

"""# **Get Train Test Split**"""

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=2529)

x_train.shape, x_test.shape, y_train.shape, y_test.shape

"""# **Get Model Train**"""

from sklearn.ensemble import RandomForestRegressor

rfr = RandomForestRegressor(random_state=2529)

rfr.fit(x_train, y_train)

"""# **Get Model Prediction**"""

y_pred = rfr.predict(x_test)

y_pred.shape

y_pred

"""# **Get Model Evaluation**"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

mean_squared_error(y_test, y_pred)

mean_absolute_error(y_test, y_pred)

r2_score(y_test, y_pred)

"""# **Get Visualization of Actual Vs Predicted Results**"""

import matplotlib.pyplot as plt

plt.scatter(y_test, y_pred)
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.title('Actual Price vs Predicted Price')
plt.show()

